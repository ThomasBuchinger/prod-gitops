


controllers:
  main:
    containers:
      main:
        image:
          tag: v2.3.1
#         env:
#           REDIS_HOSTNAME: '{{ printf "%s-valkey" .Release.Name }}'
#           IMMICH_MACHINE_LEARNING_URL: '{{ printf "http://%s-machine-learning:3003" .Release.Name }}'
#           # Add the env vars to connect to your database here.

immich:
  metrics:
    enabled: true
  persistence:
    library:
      existingClaim: immich-library-local
  # ref: https://immich.app/docs/install/config-file/
  configuration:
    storageTemplate:
      enabled: true
      template: "{{y}}/{{y}}-{{MM}}-{{dd}}/{{filename}}"

# Dependencies

valkey:
  enabled: true
  controllers:
    main:
      containers:
        main:
          image:
            repository: docker.io/valkey/valkey
            tag: 9.0-alpine@sha256:b4ee67d73e00393e712accc72cfd7003b87d0fcd63f0eba798b23251bfc9c394
            pullPolicy: IfNotPresent
  persistence:
    data:
      enabled: false
#       size: 1Gi
#       # Optional: Set this to persistentVolumeClaim to keep job queues persistent
#       type: emptyDir
#       accessMode: ReadWriteOnce
#       # storageClass: your-class

# Immich components
# server:
#   enabled: true
#   controllers:
#     main:
#       containers:
#         main:
#           image:
#             repository: ghcr.io/immich-app/immich-server
#             pullPolicy: IfNotPresent
# #   ingress:
#     main:
#       enabled: false
#       annotations:
#         # proxy-body-size is set to 0 to remove the body limit on file uploads
#         nginx.ingress.kubernetes.io/proxy-body-size: "0"
#       hosts:
#         - host: immich.local
#           paths:
#             - path: "/"
#               service:
#                 identifier: main
#       tls: []

machine-learning:
  enabled: true
#   controllers:
#     main:
#       containers:
#         main:
#           image:
#             repository: ghcr.io/immich-app/immich-machine-learning
#             pullPolicy: IfNotPresent
#           env:
#             TRANSFORMERS_CACHE: /cache
#             HF_XET_CACHE: /cache/huggingface-xet
#             MPLCONFIGDIR: /cache/matplotlib-config
  persistence:
    cache:
      enabled: true
      size: 10Gi
#       # Optional: Set this to persistentVolumeClaim to avoid downloading the ML models every start.
#       type: emptyDir
      accessMode: ReadWriteOnce
      storageClass: "local-path"